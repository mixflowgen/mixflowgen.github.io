<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture</title>
    <meta property="og:description" content="MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@">
    <meta name="twitter:title" content="MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture">

	    <link rel="stylesheet" href="style.css?v=4">

    <script>
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['\\[', '\\]'], ['$$', '$$']]
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>

  <body>
    <header class="header-container">
      <div class="header-inner">
        <div class="header-content">
          <h1>MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture</h1>
          <p>
            A post-training approach for diffusion models that leverages slowed interpolation mixture to reduce the trainingâ€“testing discrepancy (exposure bias).
          </p>
          <div class="button-container">
            <a href="https://arxiv.org/abs/2512.19311" class="button">Paper</a>
            <a href="https://github.com/fudan-generative-vision/MixFlow" class="button">Code</a>
          </div>
        </div>
      </div>
    </header>

    <div class="byline">
      <div class="byline-container">
        <div class="byline-column">
          <h3>Authors</h3>
          <p><a href="https://scholar.google.com/citations?user=QeQnG7IAAAAJ&hl=zh-CN" class="author-link">Hui Li</a><sup>1</sup></p>
          <p><a href="https://scholar.google.com.hk/citations?user=Q4LVvegAAAAJ&hl=zh-CN" class="author-link">Jiayue Lyu</a><sup>1</sup></p>
          <p><a href="https://g-u-n.github.io/" class="author-link">Fu-Yun Wang</a><sup>2</sup></p>
          <p><a href="https://github.com/Kaihui-Cheng" class="author-link">Kaihui Cheng</a><sup>1</sup></p>
          <p><a href="https://sites.google.com/site/zhusiyucs/home" class="author-link">Siyu Zhu</a><sup>1,4,5</sup></p>
          <p><a href="https://jingdongwang2017.github.io/" class="author-link">Jingdong Wang</a><sup>3</sup></p>
        </div>
        <div class="byline-column">
          <h3>Affiliations</h3>
          <p class="affiliation-link"><sup>1</sup> Fudan University</p>
          <p class="affiliation-link"><sup>2</sup> The Chinese University of Hong Kong</p>
          <p class="affiliation-link"><sup>3</sup> Baidu</p>
          <p class="affiliation-link"><sup>4</sup> Shanghai Innovation Institute</p>
          <p class="affiliation-link"><sup>5</sup> Shanghai Academy of AI for Science</p>
        </div>
        <div class="byline-column">
          <h3>Resources</h3>
          <p><a href="https://arxiv.org/abs/2512.19311" class="affiliation-link">Paper</a></p>
          <p><a href="https://github.com/fudan-generative-vision/MixFlow" class="affiliation-link">Code</a></p>
        </div>
      </div>
    </div>

    <div class="page">
      <aside class="toc" aria-label="Contents">
        <h4>Contents</h4>
        <a href="#overview">Overview</a>
        <a href="#slow-flow">Slow Flow Phenomenon</a>
        <a href="#mixflow">MixFlow</a>
        <a href="#code-compare">Easy Implementation</a>
        <a href="#results">Results</a>
        <a href="#citation">Citation</a>
      </aside>

      <main class="content">
        <section id="overview">
          <h2>Overview</h2>
          <p>
            This paper studies the training-testing discrepancy (a.k.a. exposure bias) problem for improving the diffusion models. During training, the input of a prediction network at one training timestep is the corresponding ground-truth noisy data that is an interpolation of the noise and the data, and during testing, the input is the generated noisy data. We present a novel training approach, named MixFlow, for improving the performance.
          </p>
          <p>
            Our approach is motivated by the Slow Flow phenomenon: the ground-truth interpolation that is the nearest to the generated noisy data at a given sampling timestep is observed to correspond to a higher-noise timestep (termed slowed timestep), i.e., the corresponding ground-truth timestep is slower than the sampling timestep.
          </p>
          <p>
            MixFlow leverages the interpolations at the slowed timesteps, named slowed interpolation mixture, for post-training the prediction network for each training timestep. Experiments over class-conditional image generation (including SiT, REPA, and RAE) and text-to-image generation validate the effectiveness of our approach. Our approach MixFlow over the RAE models achieve strong generation results on ImageNet: 1.43 FID (without guidance) and 1.10 (with guidance) at 256 x 256, and 1.55 FID (without guidance) and 1.10 (with guidance) at 512 x 512.
          </p>
          <figure class="figure external">
            <img src="performance.png" alt="Performance overview">
            <figcaption>Performance overview.</figcaption>
          </figure>
        </section>

        <section id="slow-flow">
          <h2>Slow Flow phenomenon</h2>
          <div class="slow-flow">
            <img src="slowflow.png" alt="Slow Flow illustration">
            <div class="slow-flow-text">
              <p>
                Illustrating (1) the Slow Flow phenomenon during the sampling process: the timestep (y-axis), corresponding to the ground truth noisy data that is the nearest to the generated noisy data at the sampling timestep \( t \) (x-axis), is slower (with higher noise), i.e., the shading area is under the line \(x=y\); and (2) the effectiveness of MixFlow training: the range of slowed timesteps for MixFlow training is smaller and closer to the sampling steps than standard training, indicating that MixFlow training effectively alleviates the training-testing discrepancy.
              </p>
            </div>
          </div>
        </section>

        <section id="mixflow">
          <h2>MixFlow</h2>
          <div class="mix-flow">
            <img src="mixflow.png" alt="MixFlow diagram">
            <div class="mix-flow-text">
              <p>
                MixFlow samples the training timestep \(t\) from a Beta distribution \(\operatorname{Beta}(2,1)\), and samples the slowed timestep \(m_t\) from a uniform distribution \(\mathcal{U}[(1-\gamma)t, t]\). The prediction network is post-trained on the slowed interpolation mixture at each training timestep to reduce the training-testing discrepancy.
              </p>
            </div>
          </div>
        </section>

        <section id="code-compare" class="code-compare">
          <h2>Easy Implementation</h2>
          <p>
            <strong>Only 5 lines of code are modified</strong> to integrate MixFlow into the RAE implementation. Concretely, we update two functions in
            <a href="https://github.com/bytetriper/RAE/blob/main/src/stage2/transport/transport.py">transport.py</a>.
            Left: RAE; Right: MixFlow + RAE.
          </p>

          <div class="code-compare-group">
            <h3>Sample function</h3>
            <div class="code-compare-row" role="group" aria-label="Sample function (RAE | MixFlow + RAE)">
              <div class="code-panel">
                <div class="code-panel-title">(a) RAE</div>
                <pre><code data-lang="python">def sample(self, x1):
    &quot;&quot;&quot;Sampling x0 &amp; t based on shape of x1 (if needed)
      Args:
        x1 - data point; [batch, *dim]
    &quot;&quot;&quot;
    
    x0 = th.randn_like(x1)
    dist_options = self.time_dist_type.split(&quot;_&quot;)
    t0, t1 = self.check_interval(self.train_eps, self.sample_eps)
    if dist_options[0] == &quot;uniform&quot;:
        t = th.rand((x1.shape[0],)) * (t1 - t0) + t0
    # ...


    t = t.to(x1)
    t = self.time_dist_shift * t / (1 + (self.time_dist_shift - 1) * t)
    return t, x0, x1</code></pre>
              </div>
              <div class="code-panel">
                <div class="code-panel-title">(b) MixFlow</div>
                <pre><code data-lang="python" data-hl-contains="t = 1 - th.sqrt(t)">def sample(self, x1):
    &quot;&quot;&quot;Sampling x0 &amp; t based on shape of x1 (if needed)
      Args:
        x1 - data point; [batch, *dim]
    &quot;&quot;&quot;
    
    x0 = th.randn_like(x1)
    dist_options = self.time_dist_type.split(&quot;_&quot;)
    t0, t1 = self.check_interval(self.train_eps, self.sample_eps)
    if dist_options[0] == &quot;uniform&quot;:
        t = th.rand((x1.shape[0],)) * (t1 - t0) + t0
    # ...
    # Sample t from Beta(2,1)
    t = 1 - th.sqrt(t) 
    t = t.to(x1)
    t = self.time_dist_shift * t / (1 + (self.time_dist_shift - 1) * t)
    return t, x0, x1</code></pre>
              </div>
            </div>
          </div>

          <div class="code-compare-group">
            <h3>Training Losses function</h3>
            <div class="code-compare-row" role="group" aria-label="Training Losses function (RAE | MixFlow + RAE)">
              <div class="code-panel">
                <div class="code-panel-title">(c) RAE</div>
                <pre><code data-lang="python">def training_losses(self, model,  x1, model_kwargs=None):
    &quot;&quot;&quot;Loss for training the score model
    Args:
    - model: backbone model; could be score, noise, or velocity
    - x1: datapoint
    - model_kwargs: additional arguments for the model
    &quot;&quot;&quot;
    if model_kwargs == None:
        model_kwargs = {}
    
    t, x0, x1 = self.sample(x1)

    t, xt, ut = self.path_sampler.plan(t, x0, x1)




    model_output = model(xt, t, **model_kwargs)
    B, *_, C = xt.shape
    assert model_output.size() == (B, *xt.size()[1:-1], C)

    terms = {}
    terms['pred'] = model_output
    if self.model_type == ModelType.VELOCITY:
        terms['loss'] = mean_flat(((model_output - ut) ** 2))
    else: 
        # ...
            
    return terms</code></pre>
              </div>
              <div class="code-panel">
                <div class="code-panel-title">(d) MixFlow</div>
                <pre><code data-lang="python" data-hl-contains="def training_losses(self, model, x1, gamma=0.4, model_kwargs=None):|t, _, ut = self.path_sampler.plan(t, x0, x1)|mt = t + th.rand_like(t) * gamma * (1 - t)|_, xt, __ = self.path_sampler.plan(mt, x0, x1)">def training_losses(self, model, x1, gamma=0.4, model_kwargs=None):
    &quot;&quot;&quot;Loss for training the score model
    Args:
    - model: backbone model; could be score, noise, or velocity
    - x1: datapoint
    - model_kwargs: additional arguments for the model
    &quot;&quot;&quot;
    if model_kwargs == None:
        model_kwargs = {}
    
    t, x0, x1 = self.sample(x1)
    # Remove the standard interpolated xt 
    t, _, ut = self.path_sampler.plan(t, x0, x1)
    # Sample slowed timestep mt
    mt = t + th.rand_like(t) * gamma * (1 - t)
    # Compute slowed interpolation
    _, xt, __ = self.path_sampler.plan(mt, x0, x1)
    model_output = model(xt, t, **model_kwargs)
    B, *_, C = xt.shape
    assert model_output.size() == (B, *xt.size()[1:-1], C)

    terms = {}
    terms['pred'] = model_output
    if self.model_type == ModelType.VELOCITY:
        terms['loss'] = mean_flat(((model_output - ut) ** 2))
    else: 
        # ...
            
    return terms</code></pre>
              </div>
            </div>
          </div>
        </section>

	        <section id="results">
	          <h2>Results</h2>

	          <div class="result-item">
	            <div class="result-text">
	              <h3>Visualization</h3>
	              <p>
	                MixFlow generates high-fidelity images with fine-grained details and textures.
	              </p>
	            </div>
	            <div class="result-figure">
	              <img src="vis.jpg" alt="Visualization results generated by MixFlow">
	            </div>
	          </div>

	          <div class="result-item">
	            <div class="result-text">
	              <h3>Class-conditional image generation</h3>
	              <p>
	                Post-training prior SOTA class-conditional models (SiT, REPA, RAE) with MixFlow improves ImageNet gFID to 1.43 (no guidance) and 1.10 (with guidance) at 256 x 256, and 1.55 / 1.10 at 512 x 512.
              </p>
            </div>
            <div class="result-figure">
              <img src="sota_result.png" alt="Class-conditional image generation results">
            </div>
          </div>

          <div class="result-grid-2">
            <div class="result-text vs-text">
              <h3>Various sampling steps</h3>
              <p>
                MixFlow yields larger gains when sampling steps are small, where <em>Slow Flow</em> is more pronounced and sampler approximation is coarser, reducing the training-testing discrepancy.
              </p>
            </div>
            <div class="result-text t2i-text">
              <h3>Text-to-image generation</h3>
              <p>
                Applying MixFlow to text-to-image diffusion models also boosts generation quality, showing the slowed-interpolation training generalizes beyond class-conditional settings.
              </p>
            </div>
            <div class="result-figure vs-fig">
              <img src="various_steps.png" alt="Results across various sampling steps">
            </div>
            <div class="result-figure t2i-fig">
              <img src="t2i_res.png" alt="Text-to-image generation results">
            </div>
          </div>
        </section>

        <section id="citation">
          <h2>Citation</h2>
          <pre><code>@article{mixflow2025,
  title={MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture},
  author={Hui Li and Jiayue Lyu and Fu-yun Wang and Kaihui Cheng and Siyu Zhu and Jingdong Wang},
  journal={arXiv preprint arXiv:},
  year={2025}
}</code></pre>
        </section>
      </main>
    </div>

    <script>
      const tocLinks = Array.from(document.querySelectorAll('.toc a[href^="#"]'));
      const sections = tocLinks
        .map((a) => document.querySelector(a.getAttribute('href')))
        .filter(Boolean);

      if ('IntersectionObserver' in window && sections.length) {
        const observer = new IntersectionObserver(
          (entries) => {
            const visible = entries
              .filter((e) => e.isIntersecting)
              .sort((a, b) => b.intersectionRatio - a.intersectionRatio)[0];
            if (!visible) return;
            const id = visible.target.getAttribute('id');
            tocLinks.forEach((a) => a.classList.toggle('is-active', a.getAttribute('href') === `#${id}`));
          },
          { rootMargin: '-15% 0px -70% 0px', threshold: [0.01, 0.1, 0.25] }
        );
        sections.forEach((s) => observer.observe(s));
      }
    </script>

    <script>
      const CODE_KEYWORDS = new Set([
        'def',
        'return',
        'if',
        'elif',
        'else',
        'for',
        'while',
        'in',
        'and',
        'or',
        'not',
        'assert',
        'None',
        'True',
        'False'
      ]);

      function escapeHtml(value) {
        return value
          .replace(/&/g, '&amp;')
          .replace(/</g, '&lt;')
          .replace(/>/g, '&gt;')
          .replace(/"/g, '&quot;')
          .replace(/'/g, '&#39;');
      }

	      function highlightCodeSegment(segment) {
	        const escaped = escapeHtml(segment);
	        const withNumbers = escaped.replace(/\b\d+(?:\.\d+)?\b/g, (m) => `<span class="tok num">${m}</span>`);
	        return withNumbers.replace(/\b[A-Za-z_][A-Za-z0-9_]*\b/g, (word) => {
	          if (!CODE_KEYWORDS.has(word)) return word;
	          return `<span class="tok kw">${word}</span>`;
	        });
	      }

	      function renderCodeWithStrings(source) {
	        const stringRe = /(['"])(?:\\.|(?!\1)[^\\\n])*\1/g;
	        let out = '';
	        let lastIndex = 0;
	        for (const match of source.matchAll(stringRe)) {
	          const index = match.index ?? 0;
	          out += highlightCodeSegment(source.slice(lastIndex, index));
	          out += `<span class="tok str">${escapeHtml(match[0])}</span>`;
	          lastIndex = index + match[0].length;
	        }
	        out += highlightCodeSegment(source.slice(lastIndex));
	        return out;
	      }

	      function renderPythonLines(source, highlightContains) {
	        const lines = source.replace(/\r\n/g, '\n').split('\n');
	        const highlightTargets = (highlightContains || []).filter(Boolean);
	        let inTriple = null;

        function renderLine(line) {
          const indentMatch = line.match(/^\s+/);
          const indent = indentMatch ? indentMatch[0] : '';
          const rest = line.slice(indent.length);

          if (inTriple) {
            if (rest.includes(inTriple)) inTriple = null;
            return `<span class="tok str">${escapeHtml(line)}</span>`;
          }

          if (rest.startsWith('"""') || rest.startsWith("'''")) {
            const delimiter = rest.startsWith('"""') ? '"""' : "'''";
            const count = rest.split(delimiter).length - 1;
            if (count === 1) inTriple = delimiter;
            return `<span class="tok str">${escapeHtml(line)}</span>`;
          }

          if (rest.startsWith('#')) {
            return `<span class="tok com">${escapeHtml(line)}</span>`;
          }

          const commentIndex = line.indexOf('#');
          const codePart = commentIndex >= 0 ? line.slice(0, commentIndex) : line;
          const commentPart = commentIndex >= 0 ? line.slice(commentIndex) : '';

	          const codeIndentMatch = codePart.match(/^\s+/);
	          const codeIndent = codeIndentMatch ? codeIndentMatch[0] : '';
	          const codeRest = codePart.slice(codeIndent.length);

	          let renderedCode = '';
	          if (codeRest.startsWith('def ')) {
	            const match = codeRest.match(/^def\s+([A-Za-z_][A-Za-z0-9_]*)/);
	            if (match) {
	              const beforeName = 'def ';
	              const fnName = match[1];
	              const afterName = codeRest.slice((beforeName + fnName).length);
	              renderedCode =
	                escapeHtml(codeIndent) +
	                `<span class="tok kw">def</span> ` +
	                `<span class="tok fn">${escapeHtml(fnName)}</span>` +
	                renderCodeWithStrings(afterName);
	            } else {
	              renderedCode = renderCodeWithStrings(codePart);
	            }
	          } else {
	            renderedCode = renderCodeWithStrings(codePart);
	          }

          const renderedComment = commentPart ? `<span class="tok com">${escapeHtml(commentPart)}</span>` : '';
          return `${renderedCode}${renderedComment}`;
        }

        return lines
          .map((line) => {
            const isHighlighted = highlightTargets.some((target) => line.includes(target));
            const klass = isHighlighted ? 'code-line is-hlt' : 'code-line';
            return `<span class="${klass}">${line.length ? renderLine(line) : '&nbsp;'}</span>`;
          })
          .join('');
      }

      document.querySelectorAll('code[data-lang="python"]').forEach((codeNode) => {
        const rawText = codeNode.textContent || '';
        const highlightContains = (codeNode.getAttribute('data-hl-contains') || '').split('|');
        codeNode.innerHTML = renderPythonLines(rawText, highlightContains);
      });
    </script>
  </body>
</html>
